# DistilBERT_BiLSTM_BERT_SentimentAnalysis-IMDB

To understand how different deep learning approaches interpret text sentiment, we evaluated three models on the IMDB movie reviews dataset. Our project compares BiLSTM, DistilBERT, and BERT to assess how recurrent and transformer-based architectures perform on the same classification task. All three achieved strong accuracy, with BiLSTM performing best (87.70%), followed by DistilBERT (86.30%) and BERT (80.80%). These results highlight the strengths and limitations of each architecture in processing and understanding sentiment in text.
<img width="3696" height="34" alt="image" src="https://github.com/user-attachments/assets/e3c3a661-2558-4384-ad63-7ac6d56d204c" />
